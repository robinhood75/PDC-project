{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def channel(chanInput):\n",
    "    chanInput = torch.clip(chanInput,-1,1)\n",
    "    erasedIndex = rd.randint(0,2)\n",
    "    chanInput[erasedIndex:len(chanInput):3] = 0\n",
    "\n",
    "    return chanInput + torch.empty(chanInput.shape).normal_(std=torch.sqrt(torch.tensor(5)))\n",
    "\n",
    "class System_MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "        nn.Linear(7, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(64),\n",
    "            \n",
    "        nn.Linear(64,256),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(256),\n",
    "            \n",
    "        nn.Linear(256, 700)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "        nn.Linear(700, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(256),\n",
    "            \n",
    "        nn.Linear(256, 128)\n",
    "        )\n",
    "        \n",
    "    def forward(self, char):\n",
    "        encoded_char = self.encoder(char)\n",
    "        with torch.no_grad():\n",
    "            channel_output = channel(encoded_char)\n",
    "        decoded_char = self.decoder(channel_output)\n",
    "        \n",
    "        return decoded_char, encoded_char\n",
    "    \n",
    "class System_CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "        nn.ConvTranspose1d(1, 20, 6),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(20),\n",
    "        \n",
    "        nn.ConvTranspose1d(20, 35, 9),\n",
    "        nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "        nn.Conv1d(35, 16, 11),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(16),\n",
    "            \n",
    "        nn.Flatten(),\n",
    "        nn.Linear(160, 128)\n",
    "        )\n",
    "        \n",
    "    def forward(self, char):\n",
    "        char = char.reshape(char.size(0),1,-1)\n",
    "        encoded_char = self.encoder(char)\n",
    "        with torch.no_grad():\n",
    "            channel_output = channel(encoded_char)\n",
    "        channel_output = channel_output.reshape(channel_output.size(0), 35, 20)\n",
    "        decoded_char = self.decoder(channel_output)\n",
    "        \n",
    "        return decoded_char, encoded_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(nb_samples):\n",
    "    return torch.empty(nb_samples,7).random_(2)\n",
    "\n",
    "def create_targets(bin_list):\n",
    "    bin_list = bin_list.flip(-1)\n",
    "    int_target = torch.sum(bin_list*torch.tensor([2**k for k in range(7)]), -1)\n",
    "    targets = torch.zeros((bin_list.size(0),128))\n",
    "    for k in range(bin_list.size(0)):\n",
    "        targets[k][int(int_target[k])-1] = 1.\n",
    "    return targets\n",
    "\n",
    "def train(model, data, data_targets, batch_size=100, nb_epochs=100):\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        for b in range(0, data.size(0), batch_size):\n",
    "            decoded_char, _ = model(data.narrow(0, b, batch_size))\n",
    "            loss = criterion(decoded_char, data_targets.narrow(0, b, batch_size))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_data(51000)\n",
    "data_targets = create_targets(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = System_MLP()\n",
    "train(system, data, data_targets, nb_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_errors: 3671\n"
     ]
    }
   ],
   "source": [
    "data = generate_data(10000)\n",
    "targets = create_targets(data).argmax(-1)\n",
    "output = system(data)[0].argmax(-1)\n",
    "#print(targets, output)\n",
    "print(\"nb_errors:\", torch.sum(targets != output).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
